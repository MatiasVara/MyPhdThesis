\section{Language Behavioral Interface}
	\subsection{Overview}
	\begin{itemize}
		\item To specify the coordination at language level, approaches rely on partial knowledge on the syntax and behavioral semantic of the languages they coordinate, \ie a language behavioral interface. At the model level, the notion of interface is used to expose information of model behavior in order to ease its coordination (see Section~\ref{ch:background}). Similarly, at language level, a behavioral interface is used to expose only a part of the syntax and semantic of language to ease its coordination. In this sense, a language behavioral interface is specific for coordination purpose.   
		
		\item In the state of art approaches, the notion of language behavioral varies depending on the approach. For example in Ptolemy~\cite{ptoleframebib} and ModHel'X~\cite{modhelxbib}, the behavior of models is described by a Director that implements a domain, \eg FSM, DE, SDF. The implementation of a domain is done in Java. To support the communication between different domains, each director has a Java interface made of methods. The interface provides a homogeneous view of the behavioral semantics of the domain. Each method has a semantics that is expressed in natural language. For instance, a part of the \emph{fire()} function description is: ``\emph{Typically, the fire() method performs the computation associated with an actor}''. Then, the framework encodes how different directors communicate by specifying how methods from interfaces are invoked. 
		%To summarize, these approaches proposed a notion of an language behavioral interface which is generic, made of methods in java, and relies on a naming convention to identify the semantics. This remains very informal since the same methods may be have a different meaning depending on the domain.    
		
		%\footnote{the Executable interface, cf. http://chess.eecs.berkeley.edu/ptexternal/src/ptII/doc/codeDoc/ptolemy/actor/Executable.html}
		\item While in frameworks the notion of interface is clearly defined, in~\cite{dinatale} information about the syntax and semantics of the functional and platform languages is contained into the mapping language. First, it contains correspondences between syntactic elements from both languages, \eg \emph{Task}s from the functional and \emph{Cpu}s from the platform. Second, to express the semantics of such correspondences, the translation semantics of the mapping language is based on knowledge about the translation semantics of the coordinated languages. For instance, it contains the name of the methods that are generated for each subsystem in the functional language. Such methods are part of the translational semantics of the functional language. The mapping language encodes the knowledge about What elements from the languages are coordinated. Thus, the approach has a notion of interface but is implicit into the mapping language. 
		
		\item In Mascot, Matlab models are embedded into SDL models by relying on SDL wrappers. The SDL wrapper has access to a C-wrapper implemented as a set of C functions, which ultimately calls the Matlab engine through a set of C-library functions. Some of these functions are \emph{InitProcess()} that initializes a data-flow process in Matlab and \emph{OutStream()} that writes a data-flow variable in Matlab. By relying on these methods, the SDL engine drives the simulation and calls the Matlab engine to process dataflow signals. The coordination results not symmetric since the communication is only done from SDL to Matlab. In this approach, only matlab is interfaced by relying on C wrappers that act as an explicit interface.
		
		
		%\item In Mascot~\cite{mascotbib}, the coordination is not symmetric since Matlab scripts are embedded in an SDL model. \todo{As a consequence the Matlab interface is used but not the SDL interface.} The authors identified two main elements about the Matlab language. First they depict the different kinds of communication used from and to Matlab. Second they characterize the Model of Computation used by the Matlab simulation engine as being Petri Net. They based the coordination on this knowledge so that these pieces of information act as the language interface of the Matlab language.
		\end{itemize}
	\subsection{Discussion}
	\begin{itemize}
			\item We want to highlight that the notion of interface is not presented in model composition approaches. These approaches compose heterogeneous metamodels by relying on a fixed meta metamodel. However, in the case of the behavioral integration of models, the models can be built with very languages (\eg SDL and Matlab in Mascot). This results in a need of a notion of interface at language level to coordinate both languages.   
			
			\item More or less explicit, all approaches get information about the languages that they coordinate. While in Ptolemy~\cite{ptoleframebib} and Modhel'X~\cite{modhelxbib} the notion of language interface is explicit defined in the framework, Di Natale et al.~\cite{dinatale} and MASCOT~\cite{mascotbib} encode such information either in a dedicated language or in wrappers. We want to highlight that an explicit language behavioral interface enables to add support to a new language with minimum effort.
			\item For instance, in~\cite{dinatale}, the mapping language encodes the information about what elements are coordinated. This makes tedious to change a language since a developer should first identify what elements are coordinated. Conversely, in Ptolemy~\cite{ptoleframebib} and ModHel'X~\cite{modhelxbib}, that task is easy since they rely on a generic interface. 
			\item However, in these approaches, the interface only provides a list of functions in which the semantics of the methods is given by relying on their names. This remains very informal since the semantics meaning of the methods changes depending on the domain. Furthermore, a system designer has to understand very well the framework to be able to use them correctly.     
			
	    	\item At the model level,~\cite{garlansoftarchbib} explains that there are important benefits of using events (with implicit invocation) in the component interfaces because it provides strong support for reuse and evolution of components. As we presented in Section~\cite{background}, in event-driven coordination approaches, events act as \emph{coordination points} and exhibit what can be coordinated. This gives a support for control and timed coordination while remaining independent of the internal model
	    	implementation. Moreover, event-driven coordinations are exogenous; \ie, models can be coordinated without any change to their implementation, thus ensuring a complete separation between the coordination and the computational concerns.
	 	
	    	\item Several causal representations from the concurrency theory are used to capture event-based behavioral interface. A causal representation captures the concurrency, dependency and conflict relationships among actions in a particular program. For instance, an event structure~\cite{eventStructures} is a partial order of events, which specifies the, possibly timed, causality relations as well as conflict relations (\ie exclusion relations) between actions of a concurrent system. This fundamental model is powerful because it totally abstracts data and program structure to focus on the partial ordering of actions. It specifies, \emph{in extension} and \emph{in order}, the set of actions that can be observed during the program execution. An event structure can also be specified \emph{in intention} to represent the set of observable event structures during an execution (see \eg\cite{tr:ccsl} or \cite{tagmachine}).
	    	
	    	\item In~\cite{sle13-combemale} elements of event structures are reified at the language level to propose a behavioral interface based on sets of \emph{event types} and \emph{contraints}. Event types (named \dse for Domain Specific Event) are defined in the context of a metaclass of the abstract syntax (\as), and abstract the relevant semantic actions. Jointly with the \dse, related constraints give a symbolic (intentional) representation of an event structure. With such an interface, the concurrency and time-related aspects of the language behavioral semantics are explicitly exposed and the coordination is event-driven and non intrusive.
	    	\item Then, for each model conforming to the language, the model behavioral interface is a specification, in intention, of an event structure whose events (named \mse for Model Specific Event) are instances of the \dse defined in the language interface. While \dse are attached to a metaclass, \mse are linked to one of its instances. The causality and conflict relations of the event structure are a model-specific unfolding of the constraints specified in the language behavioral interface. Just like event structures were initially introduced to unfold the execution of Petri nets, we use them here to unfold the execution of models.
	    	
	    	\end{itemize}
	    	
	    	
	    				%\item In~\cite{taminghetero}, authors rely on the interface automata to specify the 
	    				%\item An interesting research direction could be to adapt the notion of interface automata proposed in~\cite{henzingerIA} to specify the acceptable protocol between the calls of the functions that implements the semantics of the language. 
	    				
	    				
	    				%However, because the language interface definition used in \cite{ptolemybib} and \cite{modhelxbib} provides only a list of functions, it requires a deep understanding of the underlying framework to be able to specify correct coordination patterns. A naming convention on the name of the methods remains very informal since the same methods may be have a different meaning depending on the domain.        
	    				
	    				%\item All the approaches studied retrieve information on the syntax and/or behavioral semantics of the languages they coordinate. Only \cite{ptolemybib} and \cite{modhelxbib} made explicit the notion of interface; \cite{MarcoModels2014} and \cite{mascotbib} retrieved the information implicitly from the definition of the languages. 
	    				%Using an explicit language interface is a way to obtain a language independent representation of the behavioral semantics. In this case, the approaches can add support to new languages with a minimum effort since they are seen homogeneously. However, because the language interface definition used in \cite{ptolemybib} and \cite{modhelxbib} provides only a list of functions, it requires a deep understanding of the underlying framework to be able to specify correct coordination patterns. 
	    				
	    				%\item This task can be helped by .... 
	    				%\item \todo{An interesting research direction could be to adapt the notion of interface automata proposed in~\cite{henzingerIA} to specify the acceptable protocol between the calls of the functions that implements the semantics of the language.} 
	    				