\section{Language Behavioral Interface}
	\subsection{Overview}
The \emph{Language Behavioral Interface} provides \emph{What} can be coordinated. It is a (partial) view over the syntax and the behavioral semantics of a language. The goal of the interface is to homogenize the view of different languages. It is also an explicit way to define how the language can be coordinated. Such a representation varies from one approach to other. In the following, we present how each approach partially represents the languages that coordinate.

	\subsection{Comparison}
		\begin{itemize}
		
			
			\item In Ptolemy~\cite{ptolemybib} and ModHel'X~\cite{modhelxbib}, the coordinated models are all conforming a unique abstract syntax but with different behavioral semantics. Both approaches are based on the notion of \emph{Director}, which encodes the behavioral semantics in Java. A \emph{Director} implements a specific Java interface\footnote{the Executable interface, cf.} %\url{http://chess.eecs.berkeley.edu/ptexternal/src/ptII/doc/codeDoc/ptolemy/actor/Executable.html}}
			, which provides an homogeneous view of the behavioral semantics of a language by enforcing the prototype of the functions used to encode the semantics. The semantics behind the methods are given in a natural language. For instance, a part of the \emph{fire()} function description is: ``\emph{Typically, the fire() method performs the computation associated with an actor}''. The function prototypes, together with their informal description provides an homogeneous view of the semantics of the languages, which is used to specify the coordination pattern. It can also be noticed that the name of the director usually brings some semantics to the people aware of Model of Computation and can be considered as part of the language interface. However, using the director name remains very informal.
			
			\item In~\cite{dinatale}, the mapping language only has partial information about the syntax of both the functional and the platform languages. The mapping language references only some of the syntactic elements from both languages (\eg \emph{Task}s and \emph{Cpu}s). In addition, the translational semantics of the mapping language is based on the knowledge about the translational semantics of the platform and functional languages. More precisely the mapping semantics needs to know about the naming conventions from the other translational semantics. In~\cite{dinatale}, this required knowledge is kept implicit and hard coded in the translation semantics of the mapping language. However, this information about the language semantics could be exposed in a language interface to avoid hard coding it. 
			
			\item In Mascot~\cite{mascotbib}, the coordination is not symmetric since Matlab scripts are embedded in an SDL model. \todo{As a consequence the Matlab interface is used but not the SDL interface.} The authors identified two main elements about the Matlab language. First they depict the different kinds of communication used from and to Matlab. Second they characterize the Model of Computation used by the Matlab simulation engine as being Petri Net. They based the coordination on this knowledge so that these pieces of information act as the language interface of the Matlab language. \todo{On the other side, it is mandatory in the Matlab script to use the same name for the stream then the name of the signals from and to the SDL wrappers of the SDL model. Consequently, it means this approach relies on naming convention to specify the correspondence matching.}
		\end{itemize}
	\subsection{Discussion}
	\begin{itemize}
	
	    	\item All the approaches studied retrieve information on the syntax and/or behavioral semantics of the languages they coordinate. Only \cite{ptolemybib} and \cite{modhelxbib} made explicit the notion of interface; \cite{MarcoModels2014} and \cite{mascotbib} retrieved the information implicitly from the definition of the languages. 
	    	Using an explicit language interface is a way to obtain a language independent representation of the behavioral semantics. In this case, the approaches can add support to new languages with a minimum effort since they are seen homogeneously. However, because the language interface definition used in \cite{ptolemybib} and \cite{modhelxbib} provides only a list of functions, it requires a deep understanding of the underlying framework to be able to specify correct coordination patterns. 
	    	\todo{An interesting research direction could be to adapt the notion of interface automata proposed in~\cite{henzingerIA} to specify the acceptable protocol between the calls of the functions that implements the semantics of the language.} 
	    	
	    	\item At the model level, \cite{garlansoftarchbib} explains that there are important benefits of using events (with implicit invocation) in the component interfaces because it provides strong support for reuse and evolution of components. 
	    	In~\cite{coordinainterfacebib}, authors go further by proposing a component interface that contains events but also properties specified in a temporal logic language. These properties abstract the behavior of the components.
	    	
	    	\item \todo{Some coordination languages deal with the complexity of model behaviors by treating models as black boxes encapsulated within the boundary of an interface. A model behavioral interface gives a partial representation of the model behavior therefore easing the coordination of behavioral models. However, it is not uniquely defined and may vary depending on approaches. For instance, in \emph{Opus}~\cite{Opus}, the interface is a list of methods provided by the model. Other approaches abstract away the non-relevant parts of the behavior of models as events~\cite{eventStructures} (also named signals in~\cite{lee1998framework}). These approaches focus on events and how they are related to each other through causal, timed or synchronization relationships. Following the same idea, \emph{control-driven} coordination languages rely on a model behavioral interface made of explicit events~\cite{rapide,esperbib,coordinainterfacebib}. While in Rapide~\cite{rapide}, the interface is only a set of events acceptable by the model, some other approaches go further and also exhibit a part of the internal concurrency. This is the case of~\cite{coordinainterfacebib} where authors propose an interface that contains services and events, but also properties that express requirements on the behavior of the components. Such requirements act as a contract and can be checked during the coordination to ensure a correct behavior. In these approaches, the model behavioral interface provides information to coordinate the behavior of a model. In particular, in event-driven coordination approaches events act as ``coordination points" and exhibit what can be coordinated. This gives a support for control and timed coordination while remaining independent of the internal model implementation. Moreover, event-driven coordinations are non intrusive; \ie models can be coordinated without any change to their implementation, thus ensuring a complete separation between the coordination and the computational concerns. Several causal representations from the concurrency theory are used to capture event-based behavioral interface. A causal representation captures the concurrency, dependency and conflict relationships among actions in a particular program. For instance, an event structure~\cite{eventStructures} is a partial order of events, which specifies the, possibly timed, causality relations as well as conflict relations (\ie exclusion relations) between actions of a concurrent system. This fundamental model is powerful because it totally abstracts data and program structure to focus on the partial ordering of actions. It specifies, \emph{in extension} and \emph{in order}, the set of actions that can be observed during the program execution. An event structure can also be specified \emph{in intention} to represent the set of observable event structures during an execution (see \eg\cite{tr:ccsl} or \cite{tagmachine}).}
	    	
	    	\item With the goal to provide a rich event based language interface, \cite{sle13combemalebib} proposed to specify a behavioral language interface based on the notion of symbolic event structure. The symbolic event structure is linked to both the abstract syntax and the functions implementing the semantics. It exhibits the concurrency and the causalities between the functions implementing the semantics and link them with the concepts of the language.
	    	
	    	\item \todo{In~\cite{sle13-combemale} elements of event structures are reified at the language level to propose a behavioral interface based on sets of \emph{event types} and \emph{contraints}. Event types (named \dse for Domain Specific Event) are defined in the context of a metaclass of the abstract syntax (\as), and abstract the relevant semantic actions. Jointly with the \dse, related constraints give a symbolic (intentional) representation of an event structure. With  such an interface, the concurrency and time-related aspects of the language behavioral semantics are explicitly exposed and the coordination is event-driven and non intrusive.}
	    	\item \todo{Then, for each model conforming to the language, the model behavioral interface is a specification, in intention, of an event structure whose events (named \mse for Model Specific Event) are instances of the \dse defined in the language interface. While \dse are attached to a metaclass, \mse are linked to one of its instances. The causality and conflict relations of the event structure are a model-specific unfolding of the constraints specified in the language behavioral interface. Just like event structures were initially introduced to unfold the execution of Petri nets, we use them here to unfold the execution of models.}
	    	\end{itemize}